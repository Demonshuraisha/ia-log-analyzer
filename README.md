# IA Log Analyzer

![License](https://img.shields.io/badge/license-MIT-green)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Elasticsearch](https://img.shields.io/badge/Elasticsearch-8%2F9-orange)
![Status](https://img.shields.io/badge/status-stable-success)

Analyseur de journaux automatis√© avec Intelligence Artificielle (IA) et alertes, con√ßu pour surveiller, r√©sumer et d√©tecter les incidents critiques dans vos logs applicatifs ou syst√®mes.

## üöÄ Fonctionnalit√©s principales

- **Collecte automatique** des logs depuis Elasticsearch
- **D√©tection intelligente** d'incidents, erreurs, probl√®mes de s√©curit√© ou de performance via IA (Google Gemini)
- **Alertes automatiques** par e-mail en cas de probl√®me critique
- **Gestion d'√©tat** pour chaque client (pas de doublons, continuit√© assur√©e)
- **Enrichissement des r√©sultats** (m√©tadonn√©es, √©chantillons, etc.) pour faciliter l'analyse dans Kibana
- **Configuration flexible** via variables d'environnement

## üõ†Ô∏è Pr√©requis

- Python 3.8+
- Pile **ELK (Elasticsearch + Kibana + Filebeat/Logstash) install√©e et fonctionnelle ‚Äì OBLIGATOIRE**
  - Test√© avec Elasticsearch 8/9.
  - Les logs doivent √™tre ing√©r√©s (ex: via Filebeat ‚Üí `filebeat-*`).
- Une cl√© API **Google Gemini** (https://aistudio.google.com/app/apikey)
- Acc√®s SMTP pour l'envoi d'e-mails (optionnel)

### ‚úÖ V√©rification rapide de l'environnement ELK

1. V√©rifier Elasticsearch est UP:
   ```bash
   curl -s http://localhost:9200 | jq . # ou simplement curl http://localhost:9200
   ```
2. V√©rifier un index de logs existe (ex: Filebeat):
   ```bash
   curl -s http://localhost:9200/_cat/indices/filebeat-*?v
   ```
3. V√©rifier l'acc√®s √† Kibana: `http://localhost:5601` (ou l‚ÄôURL de votre instance)

## üì¶ Installation

1. Clonez le d√©p√¥t :
   ```bash
   git clone https://github.com/Demonshuraisha/ia-log-analyzer.git
   
   cd ia-log-analyzer
   ```
2. Cr√©ez un environnement virtuel et activez-le :
   ```bash
   python -m venv env
   source env/bin/activate  # ou .\env\Scripts\activate sous Windows
   ```
3. Installez les d√©pendances :
   ```bash
   pip install -r requirements.txt
   ```

## ‚öôÔ∏è Configuration

Cr√©ez un fichier `.env` (ou exportez les variables d'environnement) avec les param√®tres suivants :

```env
# Elasticsearch
ES_HOST=http://localhost:9200
ES_USER=elastic
ES_PASSWORD=changeme
LOG_INDEX_PATTERN=filebeat-*
ANALYSIS_STATE_INDEX=ia-analysis-state
IA_RESULTS_INDEX=ia-analysis-results
CLIENT_ID_FIELD=host.name.keyword

# API IA
GEMINI_API_KEY=sk-xxxxxxx

# Script
ANALYSIS_INTERVAL_SECONDS=300
MAX_LOGS_PER_BATCH=50
INITIAL_LOOKBACK_SECONDS=3600
ACTIVE_CLIENTS_LOOKBACK_TIME=24h

# Notifications e-mail
ENABLE_EMAIL_NOTIFICATIONS=True
SMTP_SERVER=smtp.example.com
SMTP_PORT=587
SMTP_USERNAME=monuser
SMTP_PASSWORD=monpass
EMAIL_FROM=ia-analyzer@yourdomain.com
EMAIL_TO=admin@yourdomain.com
EMAIL_SUBJECT_PREFIX=[IA Log Analyzer Alert]
ALERT_SEVERITIES=critical,high
```

## üèÉ Exemple d'utilisation

Lancez simplement le script principal :

```bash
python main.py
```

Le script tourne en boucle, analyse les logs pour chaque client actif, envoie les r√©sultats dans Elasticsearch et alerte par e-mail si besoin.

### Ex√©cution en tant que service

Linux (systemd):
```ini
[Unit]
Description=IA Log Analyzer
After=network.target

[Service]
Type=simple
WorkingDirectory=/opt/ia-log-analyzer
EnvironmentFile=/opt/ia-log-analyzer/.env
ExecStart=/usr/bin/python3 /opt/ia-log-analyzer/main.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

Windows (Task Scheduler):
- Cr√©er une t√¢che planifi√©e qui d√©marre au boot, action: `python.exe C:\path\to\ia-log-analyzer\main.py`, d√©finir le r√©pertoire de d√©marrage.

### üîç Validation rapide apr√®s ex√©cution

- Dans Kibana ‚Üí Discover, v√©rifiez l‚Äôindex `ia-analysis-results`.
- Filtrez par `client_id` et par `@timestamp` r√©cent.
- En cas d'alerte, surveillez la bo√Æte mail configur√©e.

## üîÑ Sch√©ma du workflow

```mermaid
graph TD;
    A[Collecte clients actifs] --> B[Extraction logs par client]
    B --> C[Preparation et enrichissement des logs]
    C --> D[Analyse IA - Google Gemini]
    D --> E[Stockage des resultats dans Elasticsearch]
    D --> F{Probleme critique detecte}
    F -->|Oui| G[Envoi alerte e-mail]
    F -->|Non| H[Attente prochain cycle]
    G --> H
    E --> H
```


## üìÑ Licence

Sous licence MIT (voir `LICENSE`).

## ü§ù Contribution & contact

Les contributions sont les bienvenues !

- Auteur : Unamed
- Contact : via Github
- Issues & suggestions : via GitHub

---

## ‚ùì FAQ

**Q : Le script ne se connecte pas √† Elasticsearch, que faire ?**  
R : V√©rifiez l'URL, le port, les identifiants et que le service Elasticsearch est bien d√©marr√©. Consultez les logs pour plus de d√©tails.

**Q : Comment tester l'envoi d'e-mails d'alerte ?**  
R : Activez `ENABLE_EMAIL_NOTIFICATIONS`, configurez correctement le SMTP et d√©clenchez une alerte critique (ex : ins√©rez un log simulant une erreur critique).

**Q : Comment changer la fr√©quence d'analyse ?**  
R : Modifiez la variable d'environnement `ANALYSIS_INTERVAL_SECONDS` (en secondes) dans votre fichier `.env`.

**Q : Peut-on utiliser une autre IA que Google Gemini ?**  
R : Le code est modulaire, il suffit d'adapter le module `core/ia_api_handler.py` pour int√©grer une autre API IA.

**Q : O√π trouver les r√©sultats d'analyse ?**  
R : Les r√©sultats sont stock√©s dans l'index Elasticsearch d√©fini par `IA_RESULTS_INDEX` (par d√©faut : `ia-analysis-results`).

---

## üìù Changelog

### v1.0.0 (Initial release)
- Premi√®re version stable de l'analyseur IA de logs
- Collecte automatique des logs par client
- Analyse IA (Google Gemini) et enrichissement des r√©sultats
- Alertes e-mail en cas de probl√®me critique
- Gestion d'√©tat d'analyse par client
- Configuration flexible via variables d'environnement
